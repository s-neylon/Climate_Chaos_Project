---
title: "CPS Linking Test - SHELDUS Flood Import"
output: html_document
date: "2024-04-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(ggplot2)
library(stringr)

set.seed(1157)

```

# Notes

##(3-28-24)

Importing SHELDUS data. A lot of missing data and other analysis still to go through!

##(4-2-24)

I used ChatGPT to analyze just the hurricane damage data, and it seemed clean and nothing missing!

##(04-27-24)

THIS CODE IS FOR FLOODING DATA NOW!

### Flooding Fixes

I am now going to use the 95th percentile, so I need to change that.

I should maybe use ChatGPT to check for missing data, now that this is flooding.

Also, make sure I am capturing all states!! So get rid of code which filters for hurricane states.

##(02-15-2025)

This is to create some flooding treatment data for my CPS linking test experiment! For this, I need monthly data, and only for 2016-2019.


# Import SHELDUS

```{r}

SHELDUS_df <- read_csv(here("data/SHELDUS/sheldus_1985-2022_hurr-flood-wind.csv"),
                       col_types = cols(
  `State Name` = col_character(),
  `County Name` = col_character(),
  `County FIPS` = col_character(),
  Hazard = col_character(),
  Year = col_double(),
  Month = col_double(),
  CropDmg = col_double(),
  `CropDmg(ADJ 2022)` = col_double(),
  `CropDmgPerCapita(ADJ 2022)` = col_double(),
  PropertyDmg = col_double(),
  `PropertyDmg(ADJ 2022)` = col_double(),
  `PropertyDmgPerCapita(ADJ 2022)` = col_double(),
  Injuries = col_double(),
  InjuriesPerCapita = col_double(),
  Fatalities = col_double(),
  FatalitiesPerCapita = col_double(),
  Duration_Days = col_double(),
  Fatalities_Duration = col_double(),
  Injuries_Duration = col_double(),
  Property_Damage_Duration = col_double(),
  Crop_Damage_Duration = col_double(),
  Records = col_double())
) %>% 
  rename(
  state_name = `State Name`,
  county_name = `County Name`,
  county_FIPS = `County FIPS`,
  CropDmg_Adj2022 = `CropDmg(ADJ 2022)`,
  CropDmgPerCapita_Adj2022 = `CropDmgPerCapita(ADJ 2022)`,
  PropertyDmg_Adj2022 = `PropertyDmg(ADJ 2022)`,
  PropertyDmgPerCapita_Adj2022 = `PropertyDmgPerCapita(ADJ 2022)`
  ) %>% 
  mutate(
    county_FIPS = str_replace_all(county_FIPS, "'", "")
  )

```

## Flood Data

```{r}

flood_SHELDUS <- SHELDUS_df %>% 
  select(state_name:Month | PropertyDmg:PropertyDmgPerCapita_Adj2022 | Duration_Days | Records) %>% 
  filter(Hazard == "Flooding" & Year >= 1996)

```

# Serious Flood

Setting the flooding damage threshold at 95th percentile for now (based on some analysis I did on ChatGPT).

```{r}

# Define serious flooding damage at 95th percentile of SHELDUS counties

serious_threshold <- flood_SHELDUS %>%
  summarise(quantile_95 = quantile(PropertyDmgPerCapita_Adj2022, 0.95, na.rm = TRUE)) %>%
  pull(quantile_95)  # Extract the quantile value

# Check the calculated threshold
serious_threshold

```

```{r}

# Prepare the data
flood_SHELDUS <- flood_SHELDUS %>%
  # Define a serious flood
  mutate(serious_flood = if_else(PropertyDmgPerCapita_Adj2022 >= serious_threshold, 1, 0))

```

## Export Flood Data

```{r eval=FALSE}

write_csv(flood_SHELDUS, here("data/CPS_linking/testing/flood_SHELDUS_cpsLINK_df.csv"))

```

```{r eval=FALSE}

saveRDS(flood_SHELDUS, here("data/CPS_linking/testing/flood_SHELDUS_cpsLINK_df.rds"))

```

# Sample

```{r eval=FALSE}

sample_df <- floodSHELDUS_bds_df %>%
  slice_sample(n = 100)

```

```{r eval=FALSE}

write_csv(sample_df, here("data/SHELDUS/sample_flood_df.csv"))

```

# EDA

Hazards table

```{r eval=FALSE}

SHELDUS_df %>% 
  count(Hazard) %>% 
  arrange(desc(n))

```

Flooding damage histogram

```{r eval=FALSE}

# Creating a histogram
flood_SHELDUS %>% 
  filter(PropertyDmgPerCapita_Adj2022 > 0) %>% 
ggplot(aes(x = PropertyDmgPerCapita_Adj2022)) + 
  geom_histogram(bins = 30, fill = "blue", color = "black") +  # You can adjust the number of bins
  coord_cartesian(ylim = c(0, 50))  # Adjust the y-axis to zoom in


```

Number of treated counties per year

```{r eval=FALSE}

floodSHELDUS_bds_df %>%
  group_by(year) %>%
  summarize(treated_counties = sum(serious_flood == 1, na.rm = TRUE))

```

Duplicates?

```{r eval=FALSE}

duplicates <- floodSHELDUS_bds_df %>%
  group_by(FIPS_5, year) %>%
  filter(n() > 1) %>%
  ungroup()

```

```{r eval=FALSE}

duplicates_raw <- flood_SHELDUS %>%
  group_by(county_FIPS, Year) %>%
  filter(n() > 1) %>%
  ungroup()

```

