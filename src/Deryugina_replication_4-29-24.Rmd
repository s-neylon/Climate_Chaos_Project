---
title: "Deryugina Replication Import and Gsynth Test"
author: "Sam Neylon"
date: '2023-06-24'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
#library(gsynth)
library(fect)
library(panelView)
library(lubridate)

set.seed(02139)

```

# Notes

##(06-23-2023)

Decisions to be made:

- What to do with counties "treated" by hurricanes in the beginning of the period?
- Get rid of missing data.
- Filter for Southeast US??

##(07-20-2023)

- Limiting to 2002-2012
  - 2014 is missing some rows, but not in the sample_hurr_state variable.
  - NOTE!! Outcome (emp ratio) is almost all missing for 2013-2014
- Outcome
  - emp_rate_tot_adult = CBP employment divided by population aged 15+
  - This is what Deryugina used in paper (pg 8)

Gsynth
  I may want to switch to fect (more recent), but I will stick with gsynth for now, since the documentation is better (for DiD).
  
##(07-22-2023)

Pretreatment Periods

I need a lot of pretreatment periods for the method to work! Following Deryugina, I will add 10 years before I actually start (1992-2002). I will also add a covariate for counties which had a hurricane during this period.
  - Maybe kooky, but I guess I could just use the 'hurricane' indicator as a covariate for the pre-treatment periods??? So this would get used as a covariate for the imputation??? Maybe a 'years since hurricane' variable???
  
##(07-22-2023)

Switching over to 'fect()', since it is updated more often.

##(04-29-2024)

I'm back! After spending a lot of time with new data, I would like to re-run the Deryugina models, only I will use the SHELDUS damage data as the treatment, instead of wind speed.

##(6-7-24)

Okay, getting back to this. I will be importing new SHELDUS data (covered in 'SHELDUS_Deryugina') for all years.


# Goals of the Analysis

I want to see if my SHELDUS data creates the same effects that Deryugina saw, using SHELDUS for the treatment, and her data for the Y and covariates.

Then, I will extend her analysis beyond the years she looked at.

ISSUE 1: Lack of outcomes and covariates after 2012
  * I won't have data for after the years she has it!
  * Possible solution: I should only check that I get the same results with SHELDUS for Deryugina's years, and then I can feel free to do my own thing.
  



# Import

```{r}

h_df <- read_csv(here("data/SHELDUS/Deryugina_hurr_SHELDUS.csv"),
               col_types = cols(
  county_fips = col_character(),
  year = col_double(),
  longitude = col_double(),
  latitude = col_double(),
  state_fips = col_character(),
  cbsa = col_character(),
  cz = col_character(),
  coastal = col_double(),
  consistent_sample = col_double(),
  sample_hurr_state = col_double(),
  sample_hurr_valley = col_double(),
  wind_speed = col_double(),
  hurricane = col_double(),
  central_wind_speed = col_double(),
  central_hurr = col_double(),
  cat1_hurr = col_double(),
  cat2_hurr = col_double(),
  dollars_uniform = col_double(),
  dollars_uniform_hurr = col_double(),
  dollars_uniform_ws = col_double(),
  dollars_uniform_ws_hurr = col_double(),
  dollars_uniform_pc = col_double(),
  dollars_pc_hurr = col_double(),
  dollars_pc_ws = col_double(),
  dollars_pc_ws_hurr = col_double(),
  log_net_earnings_pc = col_double(),
  log_educ_train_assistance_pc = col_double(),
  log_medicare_pc = col_double(),
  log_public_med_benefits_pc = col_double(),
  log_ret_dis_ins_pc = col_double(),
  log_ssi_benefits_pc = col_double(),
  log_curr_trans_ind_gov_pc = col_double(),
  log_curr_trans_ind_bus_pc = col_double(),
  log_inc_maint_pc = col_double(),
  log_family_assistance_pc = col_double(),
  log_food_stamps_pc = col_double(),
  log_avg_earnings_job = col_double(),
  log_avg_wage_sal_disb = col_double(),
  log_wage_pc = col_double(),
  log_unemp_pc = col_double(),
  log_wage_pc1969 = col_double(),
  log_pop1969 = col_double(),
  population = col_double(),
  pop_adult = col_double(),
  pop_working_age = col_double(),
  land_area1970 = col_double(),
  frac_young = col_double(),
  frac_old = col_double(),
  frac_black = col_double(),
  amt_flood_payments = col_double(),
  unemp_rate_state = col_double(),
  state_net_earn_pc = col_double(),
  emp_rate_tot_all = col_double(),
  emp_rate_tot_adult = col_double(),
  emp_rate_tot_wa = col_double(),
  emp_rate_REIS_all = col_double(),
  emp_rate_REIS_adult = col_double(),
  emp_rate_REIS_wa = col_double(),
  emp_rate1969 = col_double(),
  frac_young1969 = col_double(),
  frac_old1969 = col_double(),
  frac_black1969 = col_double(),
  FIPS_5 = col_character(),
  PropertyDmg = col_double(),
  PropertyDmg_Adj2022 = col_double(),
  PropertyDmgPerCapita_Adj2022 = col_double(),
  SHELDUS = col_double(),
  pre_79 = col_double(),
  serious_hurr = col_double(),
  treatment = col_double(),
  first_hurr_year = col_double(),
  group = col_double()
               ))


```

# Data

## (NO) Treatment Variables 

NO! THESE ARE WIND SPEED!

Maybe add them later as a comparison.

### hurricane - date filter

```{r eval=FALSE}

h_df <- h_df %>% 
  mutate(
    hurr_79.02 = ifelse(hurricane == 1 & year >= 1979 & year <= 2002, 1, 0)
  )

```

### 'treatment'

```{r eval=FALSE}

# Prepare the data
h_df <- h_df %>%
  # Group by county
  group_by(FIPS_5) %>%
  # Create the treatment variable
  mutate(treatment = cummax(hurr_79.02)) %>%
  ungroup()

```

### 'group' variable

```{r eval=FALSE}

floodSHELDUS_bds_df <- floodSHELDUS_bds_df %>%
  arrange(FIPS_5, year) %>%
  group_by(FIPS_5) %>%
  mutate(
    first_hurr_year = ifelse(any(hurricane == 1), min(year[hurricane == 1]), NA_real_),
    group = ifelse(is.na(first_hurr_year), 0, first_hurr_year)
  ) %>%
  ungroup()

```

# Gsynth Data Exploration

## Panelview

```{r eval=T}

panelview(emp_rate_tot_adult ~ h_persist, data = h_df, index = c("county_fips", "date"), pre.post = TRUE, by.timing = TRUE)

```

Graph of results - I have to figure out how to filter the dates and counties somehow, it can't show them all this way.

```{r eval=FALSE}

panelview(emp_rate_tot_adult ~ h_persist, data = h_df, 
          index = c("county_fips", "date"), type = "outcome", 
          main = "Emp Rate", 
          by.group = TRUE)

```


# EDA

```{r eval=TRUE}

h_df %>% count(year)

```

### Hurricane Count

```{r eval=TRUE}

h_df %>% group_by(county_fips) %>% mutate(h_count = sum(hurricane)) %>% ungroup() %>% count(h_count)

```

## NA on outcome

  - emp_rate_tot_adult = CBP employment divided by population aged 15+
  - This is what Deryugina used in paper (pg 8)

```{r eval=T}

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(emp_rate_tot_adult))) %>% ungroup() %>% count(NA_outcome)

```

```{r eval=TRUE}

h_df %>% group_by(year) %>% summarise(NA_outcome = sum(is.na(emp_rate_tot_adult)))

```

### Hurricane in 1 year

```{r eval=FALSE}

h_df %>% filter(year == 2001) %>% summarise(
  total = n(),
  hurricanes = sum(hurricane)
)

```

# Covariates

##(07-22-2023)

Slightly modifying Deryugina's (because I don't care about transfers), I use:

coastal   =1 if county is coastal, 0 otherwise
  NOT Coastal - unit-invariant, so like in fixed effects, this is already controlled for.
pop_pm    Density: gen pop_pm=population/land_area1970
log_pop   Log of total pop: gen log_pop = log(population)
log_wage_pc   log(wage/salary payments per capita)
frac_young    Fraction of population that is under 20 years old
frac_old    Fraction of population that is 65 and older
frac_black    Fraction of population that is black

## New Var

```{r eval=TRUE}

h_df <- h_df %>% mutate(
 pop_pm = population / land_area1970,
 log_pop = log(population)
)

```


## Missing

### Specific Var

coastal + pop_pm + log_pop + log_wage_pc + frac_young + frac_old + frac_black

```{r eval=FALSE}

# Testing Code

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(pop_pm))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(log_pop))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(log_wage_pc))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(frac_young))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(frac_old))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(frac_black))) %>% ungroup() %>% count(NA_outcome)

```

```{r eval=FALSE}

# Testing Code

filtered_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(pop_pm))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(log_pop))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(log_wage_pc))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(frac_young))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(frac_old))) %>% ungroup() %>% count(NA_outcome)

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(frac_black))) %>% ungroup() %>% count(NA_outcome)

```

### All

```{r eval=FALSE}

# Testing Code

test_var <- c("pop_pm")

h_df %>% group_by(county_fips) %>% mutate(NA_outcome = sum(is.na(test_var))) %>% ungroup() %>% count(NA_outcome) %>% pull(n) %>% .[[1]]

```

```{r eval=T}

covar_list <- c("coastal", "pop_pm", "log_pop", "log_wage_pc", "frac_young", "frac_old", "frac_black")

covar_miss_output <- vector("double", length(covar_list))

for (i in seq_along(covar_list)) {
  covar_miss_output[i] <- h_df %>%
    group_by(county_fips) %>% 
    summarise(NA_outcome = sum(is.na(!!sym(covar_list[i])))) %>% 
    ungroup() %>% 
    count(NA_outcome) %>% pull(n) %>% .[[1]]
}

# Count for Groups without Missing Outcome

group_count <- h_df %>%
    group_by(county_fips) %>% 
    summarise(NA_outcome = sum(is.na(emp_rate_tot_adult))) %>% 
    ungroup() %>% 
    count(NA_outcome) %>% pull(n) %>% .[[1]]

# Table

data.frame(covar = covar_list,
           diff = covar_miss_output - group_count)


```


## Filter Missing

```{r eval=T}

filtered_df <- h_df

  filtered_df <- filtered_df %>%
  group_by(county_fips) %>%
  mutate(missing_group = ifelse(any(is.na(across(all_of(covar_list)))), 1, 0)) %>% 
  filter(!any(missing_group == 1)) %>% 
  ungroup()

```



```{r eval=T}

covar_miss_output_TEST <- vector("double", length(covar_list))

for (i in seq_along(covar_list)) {
  covar_miss_output_TEST[i] <- filtered_df %>%
    group_by(county_fips) %>% 
    summarise(NA_outcome = sum(is.na(!!sym(covar_list[i])))) %>% 
    ungroup() %>% 
    count(NA_outcome) %>% pull(n) %>% .[[1]]
}

# Count for Groups without Missing Outcome

group_count <- filtered_df %>%
    group_by(county_fips) %>% 
    summarise(NA_outcome = sum(is.na(emp_rate_tot_adult))) %>% 
    ungroup() %>% 
    count(NA_outcome) %>% pull(n) %>% .[[1]]

# Table

data.frame(covar = covar_list,
           diff = covar_miss_output_TEST - group_count)


```

# fect estimation

## Subset Data

```{r eval=TRUE}

var_list <- c("county_fips", "year", "emp_rate_tot_adult", "h_persist", covar_list)

subset_df <- filtered_df %>% select(all_of(var_list))

```


## Covariates

```{r}

paste(covar_list, collapse = " + ")

```
coastal + pop_pm + log_pop + log_wage_pc + frac_young + frac_old + frac_black

*NOTE* - Removing "coastal", since it is unit-invariant, and like in fixed effects, has already been controlled for: https://github.com/xuyiqing/gsynth/issues/40



## NO Factors model

Model without estimating factors. Similar to DiD.

```{r eval=F}

out0 <- fect(emp_rate_tot_adult ~ h_persist + pop_pm + log_pop + log_wage_pc + frac_young + frac_old + frac_black, 
             data = subset_df, index = c("county_fips", "year"),
             method = "ife", se = TRUE, 
             r = 0, CV = FALSE, force = "two-way", 
             parallel = TRUE, cores = 3, nboots = 1000)

```
### Output

```{r eval=F}

print(out0)
writeLines(" \n---------- ATT by Period ----------\n ")
out0$est.att
writeLines(" \n---------- ATT averaged over all Periods ----------\n ")
out0$est.avg
writeLines(" \n---------- Betas of Time-Varying Covariates ----------\n ")
out0$est.beta

```

### Plot

```{r eval=F}

plot(out0) 

```

## Model 1

Model without estimating factors. Similar to DiD.

```{r eval=F}

out1 <- fect(emp_rate_tot_adult ~ h_persist + pop_pm + log_pop + log_wage_pc + frac_young + frac_old + frac_black, 
             data = subset_df, index = c("county_fips", "year"),
             method = "ife", se = TRUE, 
             r = c(0, 5), CV = TRUE, force = "two-way", 
             parallel = TRUE, cores = 3, nboots = 1000)

```

### Output

```{r eval=F}

print(out1)
writeLines(" \n---------- ATT by Period ----------\n ")
out1$est.att
writeLines(" \n---------- ATT averaged over all Periods ----------\n ")
out1$est.avg
writeLines(" \n---------- Betas of Time-Varying Covariates ----------\n ")
out1$est.beta

```

### Plot

```{r eval=F}

plot(out1) 

```

```{r eval=F}

plot(out1, type = "box", xlim = c(-10, 10))

```

### Cumulative Effects

```{r eval=FALSE}

fect::att.cumu(out1, period(0, 5), weighted = TRUE, plot = TRUE)

```


## Model 2: force = "none"

A model which doesn't start with two-way fixed effects - finds all factors iteratively.


```{r eval=F}

out2 <- fect(emp_rate_tot_adult ~ h_persist + pop_pm + log_pop + log_wage_pc + frac_young + frac_old + frac_black, 
             data = subset_df, index = c("county_fips", "year"),
             method = "ife", se = TRUE, 
             r = c(0, 5), CV = TRUE, force = "none", 
             parallel = TRUE, cores = 3, nboots = 1000)

```

### Output

```{r eval=F}

print(out2)
writeLines(" \n---------- ATT by Period ----------\n ")
out2$est.att
writeLines(" \n---------- ATT averaged over all Periods ----------\n ")
out2$est.avg
writeLines(" \n---------- Betas of Time-Varying Covariates ----------\n ")
out2$est.beta

```

### Plot

```{r eval=F}

plot(out2) 

```

```{r eval=F}

plot(out2, type = "box", xlim = c(-10, 10))

```

```{r eval=F}

plot(out2, type = "factors")

```

## Model 3?

Get cohorts!!
https://yiqingxu.org/packages/fect/articles/tutorial.html#average-cohort-effect

## Model 4?

Maybe cluster by state?
Weight by population??

https://github.com/xuyiqing/fect/issues/20

# Results Notes

##(07-23-2023)

Drop in N and Rise in Significance
- Looking at results of Model1, you can see that the ATT goes from non-significant at 5 years after, to significant at 6 years after. This is probably in part because a bunch of treated units didn't make it to 6 years (n drops from 262 to 240), so these missing units changed things!
  - I have to be careful here not to p-hack! Need to think through next steps...
  - I checked it out (see EDA below), and there are a lot of max 5 years of treatment, but only a few 6's. That said, this doesn't really matter, since I am taking the average treatment effect! But maybe interesting.
  
Dynamic Treatment Effects Up and Down
- Interesting that dynamic treatment effect goes up before going down...
- Is this just hiring after hurricane? To answer my question, I need to know what the Treatment effect is estimating:
  - Is it difference with previous year? With all pretreatment periods??
    - If it is difference with previous year, makes sense it would go up!
  - It is Y(1)-Y(0), where Y(0) is a counterfactual imputed by model

Model 2
- Not significant!
  - If this is a better way of estimating, does it show that there isn't an effect?
  - Get some plots and things to see what is going on with the factor loadings?
- However, you should add back in time-invariant variables! Like coastal!
  - Without FE, these are no longer absorbed...
- Plotting Loadings
  - This is only an option with gsynth...
  
## Results EDA

### 5/6 Year Hurricane

What is going on with this drop in n from 5 years after, to 6 years after?

```{r eval=FALSE}

h_df %>% group_by(county_fips) %>% mutate(h_count = sum(h_persist)) %>% count(h_persist) %>% filter(h_persist == 1 & between(n, 5, 8))

```

